{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般流程  \n",
    "1. 收集数据：可以使用任何方法。  \n",
    "2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。  \n",
    "3. 分析数据：可使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。  \n",
    "4. 训练算法：构造树的数据结构。  \n",
    "5. 测试算法：使用经验树计算错误率。  \n",
    "6. 使用算法：次步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本书使用ID3算法划分数据集（一些决策树算法采用二分法划分数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建简单的鱼鉴定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [\n",
    "    [1,1,'yes'],\n",
    "    [1,1,'yes'],\n",
    "    [1,0,'no'],\n",
    "    [0,1,'no'],\n",
    "    [0,1,'no']\n",
    "]\n",
    "labels = ['能够不浮出水面', '有鳍']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decision_trees_practice.trees import calc_shannon_ent\n",
    "\n",
    "calc_shannon_ent(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵：度量数据集的无序程度  \n",
    "熵越高，则混合的数据越多，在数据集中添加更多的分类，熵会如何变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591479170272448"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set1 = data_set\n",
    "data_set1.append([1,1,'maybe'])\n",
    "\n",
    "calc_shannon_ent(data_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_set(data_set, axis, value):\n",
    "    \"\"\"\n",
    "    按照给定特征划分数据集，筛选某个特征为指定特征值的数据\n",
    "    （然后因为是按该特征进行划分了，\n",
    "    该特征在以后的划分中就不用再出现，所以把该特征在新的列表中移除）\n",
    "    :param data_set: \n",
    "    :param axis: \n",
    "    :param value: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    ret_data_set = []\n",
    "    for feature_vec in data_set:\n",
    "        if feature_vec[axis] == value:\n",
    "            # 抽取, 把指定特征从列表中去掉，组成一个新的特征+标签的列表\n",
    "            reduced_feature_vec = feature_vec[:axis]\n",
    "            reduced_feature_vec.extend(feature_vec[axis+1:])\n",
    "            ret_data_set.append(reduced_feature_vec)\n",
    "    return ret_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "split_data_set(myDat,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_set(myDat,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最好的数据集划分方式  \n",
    "遍历整个数据集，循环计算香农熵和split_data_set函数，找到最好的特征划分方式。熵计算将会告诉我们如何划分数据集是最好的数据组织方式  \n",
    "\n",
    "使用\"信息增益最大/熵最小\"的特征进行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature_to_split(data_set):\n",
    "    # 特征数，取第一个样本即可得知，由于最后一个元素是标签，所以特征数是长度-1\n",
    "    num_features = len(data_set[0]) - 1\n",
    "    \n",
    "    # 计算整个数据集的熵（无序度）\n",
    "    base_entropy = calc_shannon_ent(data_set)\n",
    "    \n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    \n",
    "    # 遍历数据集的特征1，组成一个新的数组1， 遍历数据集的特征2，组成一个新的数组2...\n",
    "    # 我的理解是，收集每一个特征都会有哪些特征值\n",
    "    for i in range(num_features):\n",
    "        # 创建唯一的分类标签列表\n",
    "        feature_list = [example[i] for example in data_set]\n",
    "        \n",
    "        # 每一组特征值列表中，去掉重复的特征值\n",
    "        unique_vals = set(feature_list)\n",
    "        new_entropy = 0.0\n",
    "        \n",
    "        # 计算每种划分方式的信息熵\n",
    "        for value in unique_vals:\n",
    "            # 原数据集剔除了某个特征值之后的数据集\n",
    "            sub_data_set = split_data_set(data_set, i, value)\n",
    "            \n",
    "            # 该特征值在数据集中出现的概率\n",
    "            prob = len(sub_data_set)/float(len(data_set))\n",
    "            \n",
    "            # 计算划分后的子数据集的熵值（信息期望值总和）\n",
    "            new_entropy += prob * calc_shannon_ent(sub_data_set)\n",
    "            \n",
    "        # 整个数据集的熵，减去划分后的子数据集的熵，得出的是信息增益？这是什么东西呢？\n",
    "        # 为什么是减？-- 信息增益是熵的减少或者是数据无序度的减少\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        \n",
    "        if (info_gain > best_info_gain):\n",
    "            # 计算最好的信息增益\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_feature_to_split(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是说按第一个特征进行划分效果最好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果数据集已经处理了所有属性，但是类标签依然不是唯一的，此时需要决定如何定义该叶子节点\n",
    "# 通常会采用多数表决的办法决定该叶子节点的分类\n",
    "import operator\n",
    "\n",
    "def majority_cnt(class_list):\n",
    "    \"\"\"\n",
    "    从标签列表中得出出现次数最多的标签\n",
    "    :param class_list: 应该是标签的列表\n",
    "    :return: \n",
    "    \"\"\"\n",
    "    class_count = {}\n",
    "    for vote in class_list:\n",
    "        if vote not in class_count.keys():\n",
    "            class_count[vote] = 0\n",
    "        class_count[vote] += 1\n",
    "    sorted_class_count = sorted(class_count.items(), \n",
    "                                key=operator.itemgetter(1), reverse=True)\n",
    "    return sorted_class_count[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(data_set, labels):\n",
    "    \"\"\"\n",
    "    创建决策树\n",
    "    :param data_set:    数据集，应该是一个由多个[特征值1，特征值2...., 分类标签]组成的二维数组 \n",
    "    :param labels:      标签列表，包含了数据集中所有特征的标签，此算法本身其实不需要此变量\n",
    "    :return: \n",
    "    >>>data_set = [\n",
    "    [1,1,'yes'],\n",
    "    [1,1,'yes'],\n",
    "    [1,0,'no'],\n",
    "    [0,1,'no'],\n",
    "    [0,1,'no']\n",
    "    ]\n",
    "    >>>labels = ['能够不浮出水面', '有鳍']\n",
    "    >>>myTree = create_tree(data_set, labels)\n",
    "    >>>myTree\n",
    "    {'能够不浮出水面':{0:'no', 1:{'有鳍':{0:'no', 1:'yes'}}}}\n",
    "    \"\"\"\n",
    "    # data_set中每个元素中的最后一个是分类标签，把它们全部提取出来，组成分类标签的列表\n",
    "    class_list = [example[-1] for example in data_set]\n",
    "    \n",
    "    # 类别完全相同则停止继续划分\n",
    "    if class_list.count(class_list[0]) == len(class_list):\n",
    "        return class_list[0]\n",
    "    \n",
    "    # 遍历完所有特征时返回出现次数最多的\n",
    "    if len(data_set[0]) == 1:   #特征都分类完了，只剩下分类标签了，所以数组大小为1\n",
    "        return majority_cnt(class_list)\n",
    "    \n",
    "    # 特征的序号\n",
    "    best_feature = choose_best_feature_to_split(data_set)\n",
    "    # 特征的名字（只为了给出数据明确的含义，显示用）\n",
    "    best_feature_label = labels[best_feature]   # 特征的名字\n",
    "    \n",
    "    my_tree = {best_feature_label:{}}\n",
    "    \n",
    "    # 得到列表包含的所有属性值\n",
    "    del (labels[best_feature])\n",
    "    feature_values = [example[best_feature] for example in data_set]    # 特征值列表\n",
    "    unique_vals = set(feature_values)   # 特征值列表去重\n",
    "    for value in unique_vals:\n",
    "        sub_labels = labels[:]\n",
    "        my_tree[best_feature_label][value] = create_tree(\n",
    "            split_data_set(data_set, best_feature, value),\n",
    "            sub_labels\n",
    "        )\n",
    "    \n",
    "    return my_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'能够不浮出水面': {0: 'no', 1: {'有鳍': {0: 'no', 1: 'yes'}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myTree1 = create_tree(data_set, labels)\n",
    "myTree1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
