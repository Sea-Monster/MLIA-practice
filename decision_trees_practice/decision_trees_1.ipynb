{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般流程  \n",
    "1. 收集数据：可以使用任何方法。  \n",
    "2. 准备数据：树构造算法只适用于标称型数据，因此数值型数据必须离散化。  \n",
    "3. 分析数据：可使用任何方法，构造树完成之后，我们应该检查图形是否符合预期。  \n",
    "4. 训练算法：构造树的数据结构。  \n",
    "5. 测试算法：使用经验树计算错误率。  \n",
    "6. 使用算法：次步骤可以适用于任何监督学习算法，而使用决策树可以更好地理解数据的内在含义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本书使用ID3算法划分数据集（一些决策树算法采用二分法划分数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建简单的鱼鉴定数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [\n",
    "    [1,1,'yes'],\n",
    "    [1,1,'yes'],\n",
    "    [1,0,'no'],\n",
    "    [0,1,'no'],\n",
    "    [0,1,'no']\n",
    "]\n",
    "labels = ['能够不浮出水面', '有鳍']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9709505944546686"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from decision_trees_practice.trees import calc_shannon_ent\n",
    "\n",
    "calc_shannon_ent(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵：度量数据集的无序程度  \n",
    "熵越高，则混合的数据越多，在数据集中添加更多的分类，熵会如何变化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4591479170272448"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set1 = data_set\n",
    "data_set1.append([1,1,'maybe'])\n",
    "\n",
    "calc_shannon_ent(data_set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_set(data_set, axis, value):\n",
    "    \"\"\"\n",
    "    按照给定特征划分数据集，筛选某个特征为指定特征值的数据\n",
    "    （然后因为是按该特征进行划分了，\n",
    "    该特征在以后的划分中就不用再出现，所以把该特征在新的列表中移除）\n",
    "    :param data_set: \n",
    "    :param axis: \n",
    "    :param value: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    ret_data_set = []\n",
    "    for feature_vec in data_set:\n",
    "        if feature_vec[axis] == value:\n",
    "            # 抽取, 把指定特征从列表中去掉，组成一个新的特征+标签的列表\n",
    "            reduced_feature_vec = feature_vec[:axis]\n",
    "            reduced_feature_vec.extend(feature_vec[axis+1:])\n",
    "            ret_data_set.append(reduced_feature_vec)\n",
    "    return ret_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'yes'], [1, 'yes'], [0, 'no']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDat = [[1, 1, 'yes'], [1, 1, 'yes'], [1, 0, 'no'], [0, 1, 'no'], [0, 1, 'no']]\n",
    "split_data_set(myDat,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 'no'], [1, 'no']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_data_set(myDat,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择最好的数据集划分方式  \n",
    "遍历整个数据集，循环计算香农熵和split_data_set函数，找到最好的特征划分方式。熵计算将会告诉我们如何划分数据集是最好的数据组织方式  \n",
    "\n",
    "使用\"信息增益最大/熵最小\"的特征进行划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature_to_split(data_set):\n",
    "    # 特征数，取第一个样本即可得知，由于最后一个元素是标签，所以特征数是长度-1\n",
    "    num_features = len(data_set[0]) - 1\n",
    "    \n",
    "    # 计算整个数据集的熵（无序度）\n",
    "    base_entropy = calc_shannon_ent(data_set)\n",
    "    \n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "    \n",
    "    # 遍历数据集的特征1，组成一个新的数组1， 遍历数据集的特征2，组成一个新的数组2...\n",
    "    # 我的理解是，收集每一个特征都会有哪些特征值\n",
    "    for i in range(num_features):\n",
    "        # 创建唯一的分类标签列表\n",
    "        feature_list = [example[i] for example in data_set]\n",
    "        \n",
    "        # 每一组特征值列表中，去掉重复的特征值\n",
    "        unique_vals = set(feature_list)\n",
    "        new_entropy = 0.0\n",
    "        \n",
    "        # 计算每种划分方式的信息熵\n",
    "        for value in unique_vals:\n",
    "            # 原数据集剔除了某个特征值之后的数据集\n",
    "            sub_data_set = split_data_set(data_set, i, value)\n",
    "            \n",
    "            # 该特征值在数据集中出现的概率\n",
    "            prob = len(sub_data_set)/float(len(data_set))\n",
    "            \n",
    "            # 计算划分后的子数据集的熵值（信息期望值总和）\n",
    "            new_entropy += prob * calc_shannon_ent(sub_data_set)\n",
    "            \n",
    "        # 整个数据集的熵，减去划分后的子数据集的熵，得出的是信息增益？这是什么东西呢？\n",
    "        # 为什么是减？-- 信息增益是熵的减少或者是数据无序度的减少\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        \n",
    "        if (info_gain > best_info_gain):\n",
    "            # 计算最好的信息增益\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = i\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choose_best_feature_to_split(myDat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是说按第一个特征进行划分效果最好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 递归构建决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
